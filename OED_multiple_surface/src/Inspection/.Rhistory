}
data = prepare_train(file_path,random_seed,start_size,noise_level)
train = data$train
pool = data$pool
pool_all = data$pool_all
benchmark = data$benchmark
train_bad = train
errors = as.numeric()
ptm <- proc.time()
for (p in 1:(iter_num+1))
{
cat("iteration: ",p-1, "\n")
cat(" Before train size", nrow(train_bad),"\n")
model_tr = train_GP(train)
fit = model_tr$model
train = model_tr$train
cat("iteration: ",p-1,"\n")
cat("train size", nrow(train_bad),"\n")
errors[p] =  predict_benchmark(fit,train,benchmark,unfold=FALSE)
select_index = screen_index(fit,train,pool,add,method)# This part is different for different OED method
res = update_train_pool(select_index,train,train_bad,pool,pool_all,noise_level)
train = res$train
pool = res$pool
pool_all = res$pool_all
train_bad = res$train_bad
}
save_res(out_data_path,set_name,noise_level,random_seed,add,iter_num,errors,train_bad,method)
#
plot(errors)
dim(train)
dim(train_bad)
source("../setpath.R")
library(mlegp)
# args = commandArgs(TRUE)
# add = as.integer(args[1])
# iter_num = as.integer(args[2])
# pool_size = as.integer(args[3])
# start_size = as.integer(args[4])
#
# random_seed = as.integer(args[5])
# set_name = args[6]
# noise_level = as.integer(args[7])
method = "EN"
add = 3
iter_num = 40
pool_size = 500
start_size = 50
random_seed= 1
set_name = 1
noise_level = 0
file_path = file.path(data_path,paste(set_name,".csv",sep=""))
Rcodes = c("prepare_train.R","compute_kernel.R","predict_benchmark.R",
"update_train_pool.R","save_res.R","screen_index.R","train_GP.R")
for (Rcode in Rcodes) {
source(file.path(helper_path,Rcode))
}
data = prepare_train(file_path,random_seed,start_size,noise_level)
train = data$train
pool = data$pool
pool_all = data$pool_all
benchmark = data$benchmark
train_bad = train
errors = as.numeric()
ptm <- proc.time()
for (p in 1:(iter_num+1))
{
cat("iteration: ",p-1, "\n")
cat(" Before train size", nrow(train_bad),"\n")
model_tr = train_GP(train)
fit = model_tr$model
train = model_tr$train
cat("iteration: ",p-1,"\n")
cat("train size", nrow(train_bad),"\n")
errors[p] =  predict_benchmark(fit,train,benchmark,unfold=FALSE)
select_index = screen_index(fit,train,pool,add,method)# This part is different for different OED method
res = update_train_pool(select_index,train,train_bad,pool,pool_all,noise_level)
train = res$train
pool = res$pool
pool_all = res$pool_all
train_bad = res$train_bad
}
save_res(out_data_path,set_name,noise_level,random_seed,add,iter_num,errors,train_bad,method)
#
setwd("~/Git/OED/OED_multiple_surface/src/Sanity")
source("../setpath.R")
library(mlegp)
set_id = 4
noise_level = 1
random_seed = 1
method = "MI"
add = 2
iter_num = 30
pool_size = 650
start_size = 100
file_path = file.path(data_path,paste(set_id,".csv",sep=""))
Rcodes = c("prepare_train.R","compute_kernel.R","predict_benchmark.R",
"update_train_pool.R","save_res.R","screen_index.R",
"train_GP.R","max_dist.R","compute_MI_denominator.R")
for (Rcode in Rcodes) {
source(file.path(helper_path,Rcode))
}
data = prepare_train(file_path,random_seed,start_size,noise_level)
train = data$train
pool = data$pool
pool_all = data$pool_all
benchmark = data$benchmark
train_bad = train
errors = as.numeric()
dim(train)
source("../setpath.R")
library(mlegp)
set_id = 4
noise_level = 1
random_seed = 1
method = "MI"
add = 2
iter_num = 30
pool_size = 650
start_size = 300
file_path = file.path(data_path,paste(set_id,".csv",sep=""))
Rcodes = c("prepare_train.R","compute_kernel.R","predict_benchmark.R",
"update_train_pool.R","save_res.R","screen_index.R",
"train_GP.R","max_dist.R","compute_MI_denominator.R")
for (Rcode in Rcodes) {
source(file.path(helper_path,Rcode))
}
data = prepare_train(file_path,random_seed,start_size,noise_level)
train = data$train
pool = data$pool
pool_all = data$pool_all
benchmark = data$benchmark
train_bad = train
errors = as.numeric()
ptm <- proc.time()
model_tr = train_GP(train,add)
fit = model_tr$model
train = model_tr$train
cat("iteration: ",p-1,"\n")
cat("train size", nrow(train_bad),"\n")
errors[p] =  predict_benchmark(fit,train,benchmark,unfold=FALSE)
select_index = screen_index(fit,train,pool,add,method)# This part is different for different OED method
ptm <- proc.time()
dim(train)
ptm <- proc.time()
model_tr = train_GP(train,add)
fit = model_tr$model
train = model_tr$train
cat("iteration: ",p-1,"\n")
cat("train size", nrow(train_bad),"\n")
ptm1 <- proc.time()
ptm1
ptm
ptm1 - ptm
205/60
ptm2 <- proc.time()
select_index = screen_index(fit,train,pool,add,method)# This part is different for different OED method
ptm3 <- proc.time()
ptm3 - ptm2
a = ptm3 - ptm2
ptm
ptm$elapsed
ptm[3]
source("../setpath.R")
library(mlegp)
set_id = 4
noise_level = 1
random_seed = 1
method = "MI"
add = 2
iter_num = 30
pool_size = 650
start_size = 50
file_path = file.path(data_path,paste(set_id,".csv",sep=""))
Rcodes = c("prepare_train.R","compute_kernel.R","predict_benchmark.R",
"update_train_pool.R","save_res.R","screen_index.R",
"train_GP.R","max_dist.R","compute_MI_denominator.R")
for (Rcode in Rcodes) {
source(file.path(helper_path,Rcode))
}
data = prepare_train(file_path,random_seed,start_size,noise_level)
train = data$train
pool = data$pool
pool_all = data$pool_all
benchmark = data$benchmark
train_bad = train
errors = as.numeric()
times_tr = as.numeric()
times_mi = as.numeric()
i=1
dim(train)
train = rbind(train,pool[(i*3):((i+1)*3),])
dim(train)
train = rbind(train,pool[(i*3):((i+1)*3-1),])
dim(train)
source("../setpath.R")
library(mlegp)
set_id = 4
noise_level = 1
random_seed = 1
method = "MI"
add = 2
iter_num = 30
pool_size = 650
start_size = 50
file_path = file.path(data_path,paste(set_id,".csv",sep=""))
Rcodes = c("prepare_train.R","compute_kernel.R","predict_benchmark.R",
"update_train_pool.R","save_res.R","screen_index.R",
"train_GP.R","max_dist.R","compute_MI_denominator.R")
for (Rcode in Rcodes) {
source(file.path(helper_path,Rcode))
}
data = prepare_train(file_path,random_seed,start_size,noise_level)
train = data$train
pool = data$pool
pool_all = data$pool_all
benchmark = data$benchmark
train_bad = train
errors = as.numeric()
times_tr = as.numeric()
times_mi = as.numeric()
for (i in 1:10){
ptm <- proc.time()
model_tr = train_GP(train,add)
fit = model_tr$model
train = model_tr$train
cat("iteration: ",p-1,"\n")
cat("train size", nrow(train_bad),"\n")
ptm1 <- proc.time()
a = ptm1 - ptm
times_tr = c(times_tr, a[2])
errors[p] =  predict_benchmark(fit,train,benchmark,unfold=FALSE)
ptm2 <- proc.time()
select_index = screen_index(fit,train,pool,add,method)# This part is different for different OED method
ptm3 <- proc.time()
b = ptm3 - ptm2
times_mi = c(times_mi,b[3])
train = rbind(train,pool[(i*3):((i+1)*3-1),])
}
plot(times_tr)
dim(train)
dim(times_mi)
plot(times_mi)
plot(times_tr)
setwd("~/Git/OED/OED_multiple_surface/src/Three_in_One")
source("../setpath.R")
library(mlegp)
# args = commandArgs(TRUE)
# set_id = args[1]
# noise_level = as.integer(args[2])
# random_seed = as.integer(args[3])
# method = args[4]
#
# add = as.integer(args[5])
# iter_num = as.integer(args[6])
set_id = 3
noise_level = 2
random_seed = 2
method = "Random"
add = 1
iter_num = 11
pool_size = 650
start_size = 50
file_path = file.path(data_path,paste(set_id,".csv",sep=""))
Rcodes = c("prepare_train.R","compute_kernel.R","predict_benchmark.R",
"update_train_pool.R","save_res.R","screen_index.R",
"train_GP.R","max_dist.R","compute_MI_denominator.R")
for (Rcode in Rcodes) {
source(file.path(helper_path,Rcode))
}
data = prepare_train(file_path,random_seed,start_size,noise_level)
train = data$train
pool = data$pool
pool_all = data$pool_all
benchmark = data$benchmark
train_bad = train
errors = as.numeric()
ptm <- proc.time()
for (p in 1:(iter_num+1))
{
cat("iteration: ",p-1, "\n")
cat(" Before train size", nrow(train_bad),"\n")
model_tr = train_GP(train,add)
fit = model_tr$model
train = model_tr$train
cat("iteration: ",p-1,"\n")
cat("train size", nrow(train_bad),"\n")
errors[p] =  predict_benchmark(fit,train,benchmark,unfold=FALSE)
select_index = screen_index(fit,train,pool,add,method)# This part is different for different OED method
res = update_train_pool(select_index,train,train_bad,pool,pool_all,noise_level)
train = res$train
pool = res$pool
pool_all = res$pool_all
train_bad = res$train_bad
}
save_res(out_data_path,set_id,noise_level,random_seed,add,iter_num,errors,train_bad,method)
#
setwd("~/Git/OED/OED_multiple_surface/src/Three_in_One")
source("../setpath.R")
library(mlegp)
# args = commandArgs(TRUE)
# set_id = args[1]
# noise_level = as.integer(args[2])
# random_seed = as.integer(args[3])
# method = args[4]
#
# add = as.integer(args[5])
# iter_num = as.integer(args[6])
set_id = 3
noise_level = 2
random_seed = 3
method = "Random"
add = 1
iter_num = 180
pool_size = 650
start_size = 50
file_path = file.path(data_path,paste(set_id,".csv",sep=""))
Rcodes = c("prepare_train.R","compute_kernel.R","predict_benchmark.R",
"update_train_pool.R","save_res.R","screen_index.R",
"train_GP.R","max_dist.R","compute_MI_denominator.R")
for (Rcode in Rcodes) {
source(file.path(helper_path,Rcode))
}
data = prepare_train(file_path,random_seed,start_size,noise_level)
train = data$train
pool = data$pool
pool_all = data$pool_all
benchmark = data$benchmark
train_bad = train
errors = as.numeric()
ptm <- proc.time()
for (p in 1:(iter_num+1))
{
cat("iteration: ",p-1, "\n")
cat(" Before train size", nrow(train_bad),"\n")
model_tr = train_GP(train,add)
fit = model_tr$model
train = model_tr$train
cat("iteration: ",p-1,"\n")
cat("train size", nrow(train_bad),"\n")
errors[p] =  predict_benchmark(fit,train,benchmark,unfold=FALSE)
select_index = screen_index(fit,train,pool,add,method)# This part is different for different OED method
res = update_train_pool(select_index,train,train_bad,pool,pool_all,noise_level)
train = res$train
pool = res$pool
pool_all = res$pool_all
train_bad = res$train_bad
}
plot(errors)
setwd("~/Git/OED/OED_multiple_surface/src/Inspection")
setwd("~/Git/OED/OED_multiple_surface/src/Inspection")
source("../setpath.R")
library(mlegp)
# args = commandArgs(TRUE)
# set_id = args[1]
# noise_level = as.integer(args[2])
# random_seed = as.integer(args[3])
# method = args[4]
#
# add = as.integer(args[5])
# iter_num = as.integer(args[6])
set_id = 2
noise_level = 0
random_seed = 1
method = "EN"
iter_num = 180
pool_size = 650
start_size = 50
file_path = file.path(data_path,paste(set_id,".csv",sep=""))
Rcodes = c("prepare_train.R","compute_kernel.R","predict_benchmark.R",
"update_train_pool.R","save_res.R","screen_index.R",
"train_GP.R","max_dist.R","compute_MI_denominator.R")
for (Rcode in Rcodes) {
source(file.path(helper_path,Rcode))
}
data = prepare_train(file_path,random_seed,start_size,noise_level)
train = data$train
pool = data$pool
pool_all = data$pool_all
benchmark = data$benchmark
out_data_path
paste("data_",set_id,"_noise_",noise_level,"_seed_",random_seed,sep = "")
folder = paste("data_",set_id,"_noise_",noise_level,"_seed_",random_seed,sep = "")
file_name = "train_every_1_iter_180.csv"
train_selected = read.csv(file.path(out_data_path,folder,file_name))
folder = paste("data_",set_id,"_noise_",noise_level,"_seed_",random_seed,sep = "")
file_name = "train_every_1_iter_180.csv"
train_selected = read.csv(file.path(out_data_path,folder,method,file_name))
head(train_selected)
train_selected = read.csv(file.path(out_data_path,folder,method,file_name))[,2:4]
head(train_selected)
folder = paste("data_",set_id,"_noise_",noise_level,"_seed_",random_seed,sep = "")
train_name = "train_every_1_iter_180.csv"
error_name = "every_1_iter_180.csv"
train_selected = read.csv(file.path(out_data_path,folder,method,file_name))[,2:4]
errors_selected = read.csv(file.path(out_data_path,folder,method,error_name))
head(errors_selected)
plot(errors_selected[,2])
file_path = file.path(data_path,paste(set_id,".csv",sep=""))
Rcodes = c("prepare_train.R","compute_kernel.R","predict_benchmark.R",
"update_train_pool.R","save_res.R","screen_index.R",
"train_GP.R","max_dist.R","compute_MI_denominator.R")
for (Rcode in Rcodes) {
source(file.path(helper_path,Rcode))
}
data = prepare_train(file_path,random_seed,start_size,noise_level)
benchmark = data$benchmark
train = read.csv(file.path(out_data_path,folder,method,file_name))[,2:4]
seq(1,10,2)
source("../setpath.R")
library(mlegp)
# args = commandArgs(TRUE)
# set_id = args[1]
# noise_level = as.integer(args[2])
# random_seed = as.integer(args[3])
# method = args[4]
#
# add = as.integer(args[5])
# iter_num = as.integer(args[6])
set_id = 2
noise_level = 0
random_seed = 1
method = "EN"
iter_num = 180
pool_size = 650
start_size = 50
folder = paste("data_",set_id,"_noise_",noise_level,"_seed_",random_seed,sep = "")
train_name = "train_every_1_iter_180.csv"
error_name = "every_1_iter_180.csv"
train = read.csv(file.path(out_data_path,folder,method,file_name))[,2:4]
errors_selected = read.csv(file.path(out_data_path,folder,method,error_name))
file_path = file.path(data_path,paste(set_id,".csv",sep=""))
Rcodes = c("prepare_train.R","compute_kernel.R","predict_benchmark.R",
"update_train_pool.R","save_res.R","screen_index.R",
"train_GP.R","max_dist.R","compute_MI_denominator.R")
for (Rcode in Rcodes) {
source(file.path(helper_path,Rcode))
}
data = prepare_train(file_path,random_seed,start_size,noise_level)
benchmark = data$benchmark
errors = as.numeric()
source("../setpath.R")
library(mlegp)
# args = commandArgs(TRUE)
# set_id = args[1]
# noise_level = as.integer(args[2])
# random_seed = as.integer(args[3])
# method = args[4]
#
# add = as.integer(args[5])
# iter_num = as.integer(args[6])
set_id = 2
noise_level = 0
random_seed = 1
method = "EN"
iter_num = 18
pool_size = 650
start_size = 50
folder = paste("data_",set_id,"_noise_",noise_level,"_seed_",random_seed,sep = "")
train_name = "train_every_1_iter_180.csv"
error_name = "every_1_iter_180.csv"
train = read.csv(file.path(out_data_path,folder,method,file_name))[,2:4]
errors_selected = read.csv(file.path(out_data_path,folder,method,error_name))
file_path = file.path(data_path,paste(set_id,".csv",sep=""))
Rcodes = c("prepare_train.R","compute_kernel.R","predict_benchmark.R",
"update_train_pool.R","save_res.R","screen_index.R",
"train_GP.R","max_dist.R","compute_MI_denominator.R")
for (Rcode in Rcodes) {
source(file.path(helper_path,Rcode))
}
data = prepare_train(file_path,random_seed,start_size,noise_level)
benchmark = data$benchmark
errors = as.numeric()
for (p in seq(1,(iter_num+1),3))
{
end = start_size+p*add
fit =  mlegp(train[1:end,1:2],train[1:end,3])
cat("iteration: ",p-1,"\n")
cat("train size", nrow(train_bad),"\n")
errors[p] =  predict_benchmark(fit,train,benchmark,unfold=FALSE)
}
#
end
fit =  mlegp(train[1:end,1:2],train[1:end,3])
errors[p] =  predict_benchmark(fit,train,benchmark,unfold=FALSE)
head(benchmark)
head(train)
fit
d=fit[["numDim"]]
beta=fit[["beta"]]
sigma=fit[["sig2"]]
inverse=fit$invVarMatrix
mu=fit[["mu"]]
fitZ = fit$Z
nugget=fit[["nugget"]]
newcov = compute_kernel(d,beta,sigma, train,benchmark)
diag(newcov)=diag(newcov) #+nugget
mean=newcov%*%inverse%*%(fitZ - mu)+mu[1]
dim(newcov)
dim(benchmark)
dim(train)
end
dim(inverse)
end = start_size+p*add
fit =  mlegp(train[1:end,1:2],train[1:end,3])
errors[p] =  predict_benchmark(fit,train[1:end],benchmark,unfold=FALSE)
errors[p] =  predict_benchmark(fit,train[1:end,],benchmark,unfold=FALSE)
for (p in seq(1,(iter_num+1),3))
{
end = start_size+p*add
fit =  mlegp(train[1:end,1:2],train[1:end,3])
errors[p] =  predict_benchmark(fit,train[1:end,],benchmark,unfold=FALSE)
}

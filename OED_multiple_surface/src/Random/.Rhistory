fitZ = fit$Z
df=as.matrix(train)
source(file.path(helper_path,"predict_benchmark.R"))
res = predict_benchmark(inverse,d,beta,sigma, mu, nugget, nubmer,fitZ,df,data,unfold=TRUE)
mean = res[1:(length(res)/2)]
var = res[(length(res)/2+1):length(res)]
real=data[,3]
# This is the predicted mean and variance by the interface coming with the package
pred = predict(fit, data[,1:2], se.fit=TRUE)
mean_pred = pred$fit
var_pred = (pred$se.fit)^2
plot(var_pred,var)
plot(mean_pred, mean)
plot(real, mean)
plot(real, mean_pred)
mean(abs(real-mean))
source("../setpath.R")
library(mlegp)
set_name = 3
start_size = 200
data_all = read.csv(file.path(data_path,paste(set_name,".csv",sep="")), header=TRUE)
data_all = as.matrix(data_all[sample(nrow(data_all)),])
std = noise_level*0.01
train = data_all[1:start_size,]
#train = rbind(train,train,train)
#train[,3] = train[,3] + rnorm(nrow(train),sd=0.09)
data = data_all[(start_size+1):(start_size+3000),]
xx= train[,1:2]
y= train[,3]
fit=mlegp(xx,y)
#fit=mlegp(xx,y,nugget=1,nugget.known=1)
inverse=fit$invVarMatrix
d=fit[["numDim"]]
beta=fit[["beta"]]
sigma=fit[["sig2"]]
mu=fit[["mu"]]
nugget=fit[["nugget"]]
number=fit[["numObs"]]
fitZ = fit$Z
df=as.matrix(train)
source(file.path(helper_path,"predict_benchmark.R"))
res = predict_benchmark(inverse,d,beta,sigma, mu, nugget, nubmer,fitZ,df,data,unfold=TRUE)
mean = res[1:(length(res)/2)]
var = res[(length(res)/2+1):length(res)]
real=data[,3]
# This is the predicted mean and variance by the interface coming with the package
pred = predict(fit, data[,1:2], se.fit=TRUE)
mean_pred = pred$fit
var_pred = (pred$se.fit)^2
plot(var_pred,var)
plot(mean_pred, mean)
plot(real, mean)
plot(real, mean_pred)
mean(abs(real-mean))
source("../setpath.R")
library(mlegp)
set_name = 3
start_size = 250
data_all = read.csv(file.path(data_path,paste(set_name,".csv",sep="")), header=TRUE)
data_all = as.matrix(data_all[sample(nrow(data_all)),])
std = noise_level*0.01
train = data_all[1:start_size,]
#train = rbind(train,train,train)
#train[,3] = train[,3] + rnorm(nrow(train),sd=0.09)
data = data_all[(start_size+1):(start_size+3000),]
xx= train[,1:2]
y= train[,3]
fit=mlegp(xx,y)
#fit=mlegp(xx,y,nugget=1,nugget.known=1)
inverse=fit$invVarMatrix
d=fit[["numDim"]]
beta=fit[["beta"]]
sigma=fit[["sig2"]]
mu=fit[["mu"]]
nugget=fit[["nugget"]]
number=fit[["numObs"]]
fitZ = fit$Z
df=as.matrix(train)
source(file.path(helper_path,"predict_benchmark.R"))
res = predict_benchmark(inverse,d,beta,sigma, mu, nugget, nubmer,fitZ,df,data,unfold=TRUE)
mean = res[1:(length(res)/2)]
var = res[(length(res)/2+1):length(res)]
real=data[,3]
# This is the predicted mean and variance by the interface coming with the package
pred = predict(fit, data[,1:2], se.fit=TRUE)
mean_pred = pred$fit
var_pred = (pred$se.fit)^2
plot(var_pred,var)
plot(mean_pred, mean)
plot(real, mean)
plot(real, mean_pred)
mean(abs(real-mean))
start_size = 250
source("../setpath.R")
library(mlegp)
set_name = 3
start_size = 350
data_all = read.csv(file.path(data_path,paste(set_name,".csv",sep="")), header=TRUE)
data_all = as.matrix(data_all[sample(nrow(data_all)),])
std = noise_level*0.01
train = data_all[1:start_size,]
#train = rbind(train,train,train)
#train[,3] = train[,3] + rnorm(nrow(train),sd=0.09)
data = data_all[(start_size+1):(start_size+3000),]
xx= train[,1:2]
y= train[,3]
fit=mlegp(xx,y)
#fit=mlegp(xx,y,nugget=1,nugget.known=1)
inverse=fit$invVarMatrix
d=fit[["numDim"]]
beta=fit[["beta"]]
sigma=fit[["sig2"]]
mu=fit[["mu"]]
nugget=fit[["nugget"]]
number=fit[["numObs"]]
fitZ = fit$Z
df=as.matrix(train)
source(file.path(helper_path,"predict_benchmark.R"))
res = predict_benchmark(inverse,d,beta,sigma, mu, nugget, nubmer,fitZ,df,data,unfold=TRUE)
mean = res[1:(length(res)/2)]
var = res[(length(res)/2+1):length(res)]
real=data[,3]
# This is the predicted mean and variance by the interface coming with the package
pred = predict(fit, data[,1:2], se.fit=TRUE)
mean_pred = pred$fit
var_pred = (pred$se.fit)^2
plot(var_pred,var)
plot(mean_pred, mean)
plot(real, mean)
plot(real, mean_pred)
mean(abs(real-mean))
source("../setpath.R")
library(mlegp)
set_name = 3
start_size = 450
data_all = read.csv(file.path(data_path,paste(set_name,".csv",sep="")), header=TRUE)
data_all = as.matrix(data_all[sample(nrow(data_all)),])
std = noise_level*0.01
train = data_all[1:start_size,]
#train = rbind(train,train,train)
#train[,3] = train[,3] + rnorm(nrow(train),sd=0.09)
data = data_all[(start_size+1):(start_size+3000),]
xx= train[,1:2]
y= train[,3]
fit=mlegp(xx,y)
#fit=mlegp(xx,y,nugget=1,nugget.known=1)
inverse=fit$invVarMatrix
d=fit[["numDim"]]
beta=fit[["beta"]]
sigma=fit[["sig2"]]
mu=fit[["mu"]]
nugget=fit[["nugget"]]
number=fit[["numObs"]]
fitZ = fit$Z
df=as.matrix(train)
source(file.path(helper_path,"predict_benchmark.R"))
res = predict_benchmark(inverse,d,beta,sigma, mu, nugget, nubmer,fitZ,df,data,unfold=TRUE)
mean = res[1:(length(res)/2)]
var = res[(length(res)/2+1):length(res)]
real=data[,3]
# This is the predicted mean and variance by the interface coming with the package
pred = predict(fit, data[,1:2], se.fit=TRUE)
mean_pred = pred$fit
var_pred = (pred$se.fit)^2
plot(var_pred,var)
plot(mean_pred, mean)
plot(real, mean)
plot(real, mean_pred)
mean(abs(real-mean))
setwd("~/OED_all/OED_multiple_surface/src/Random")
setwd("~/OED_all/OED_multiple_surface/src/Random")
source("../setpath.R")
library(mlegp)
# args = commandArgs(TRUE)
# add = as.integer(args[1])
# iter_num = as.integer(args[2])
# pool_size = as.integer(args[3])
# repeat_time = as.integer(args[4])
# set_name = args[5]
# noise_level = args[6]
# anti_pool = args[7]
# measure = args[8]
add = 3
iter_num = 10
pool_size = 500
repeat_time = 1
set_name = 1
noise_level = 2
anti_pool = "true"
measure = "relative"
start_size = 50
# used to get the range of output
data_all = read.csv(file.path(data_path,paste(set_name,".csv",sep="")), header=TRUE)
data_all = as.matrix(data_all[sample(nrow(data_all)),])
std = noise_level*0.01
train = data_all[1:start_size,]
pool_all = data_all[(start_size+1):(start_size+1000),]
pool = pool_all[1:500,]
benchmark = data_all[(start_size+1000):nrow(data_all),]
errors = as.numeric()
p = 1
xx= train[,1:2]
y= train[,3]
fit=mlegp(xx,y)
inverse=fit$invVarMatrix
d=fit[["numDim"]]
beta=fit[["beta"]]
sigma=fit[["sig2"]]
mu=fit[["mu"]]
nugget=fit[["nugget"]]
number=fit[["numObs"]]
fitZ = fit$Z
df=as.matrix(train)
# select the top add rows and add them to train. (caveat: when indexing one row,keep the dimension)
adddata=pool[1:add,1:3,drop=FALSE]
without_noise = adddata[,3]
for (dup in 1:5) {
noises = rnorm(nrow(adddata),0,std)
adddata[,3] = without_noise + noises
train=t(data.frame(t(train),t(adddata)))
}
index = seq(1,nrow(pool),1)
total=1:dim(pool)[1]
remove=index[1:add]
errors[p] =  predict_benchmark(inverse,d,beta,sigma, mu, nugget, nubmer,fitZ,train,benchmark,measure = measure)
p
errors
setwd("~/OED_all/OED_multiple_surface/src/Random")
source("../setpath.R")
library(mlegp)
# args = commandArgs(TRUE)
# add = as.integer(args[1])
# iter_num = as.integer(args[2])
# pool_size = as.integer(args[3])
# repeat_time = as.integer(args[4])
# set_name = args[5]
# noise_level = args[6]
# anti_pool = args[7]
# measure = args[8]
add = 3
iter_num = 10
pool_size = 500
repeat_time = 1
set_name = 1
noise_level = 2
anti_pool = "true"
measure = "relative"
start_size = 50
# used to get the range of output
data_all = read.csv(file.path(data_path,paste(set_name,".csv",sep="")), header=TRUE)
data_all = as.matrix(data_all[sample(nrow(data_all)),])
std = noise_level*0.01
train = data_all[1:start_size,]
pool_all = data_all[(start_size+1):(start_size+1000),]
pool = pool_all[1:500,]
benchmark = data_all[(start_size+1000):nrow(data_all),]
data = data_all[1:pool_size,]
train= read.csv(file.path(out_data_path,"train_pool",paste(repeat_time,set_name,"noise",noise_level,sep=""), "entropy_train.csv"), header=TRUE)
# bencharmark set
dat= as.matrix(read.csv(file.path(out_data_path, "train_pool",paste(repeat_time,set_name,"noise",noise_level,sep=""),"GPsynthetic2.csv"), header=TRUE))
errors = as.numeric()
ptm <- proc.time()
source(file.path(helper_path,"predict_benchmark.R"))
source("../setpath.R")
library(mlegp)
# args = commandArgs(TRUE)
# add = as.integer(args[1])
# iter_num = as.integer(args[2])
# pool_size = as.integer(args[3])
# repeat_time = as.integer(args[4])
# set_name = args[5]
# noise_level = args[6]
# anti_pool = args[7]
# measure = args[8]
add = 3
iter_num = 10
pool_size = 500
repeat_time = 1
set_name = 1
noise_level = 2
anti_pool = "true"
measure = "relative"
start_size = 50
# used to get the range of output
data_all = read.csv(file.path(data_path,paste(set_name,".csv",sep="")), header=TRUE)
data_all = as.matrix(data_all[sample(nrow(data_all)),])
std = noise_level*0.01
train = data_all[1:start_size,]
pool_all = data_all[(start_size+1):(start_size+1000),]
pool = pool_all[1:500,]
benchmark = data_all[(start_size+1000):nrow(data_all),]
data = data_all[1:pool_size,]
train= read.csv(file.path(out_data_path,"train_pool",paste(repeat_time,set_name,"noise",noise_level,sep=""), "entropy_train.csv"), header=TRUE)
# bencharmark set
dat= as.matrix(read.csv(file.path(out_data_path, "train_pool",paste(repeat_time,set_name,"noise",noise_level,sep=""),"GPsynthetic2.csv"), header=TRUE))
errors = as.numeric()
ptm <- proc.time()
source("../setpath.R")
library(mlegp)
# args = commandArgs(TRUE)
# add = as.integer(args[1])
# iter_num = as.integer(args[2])
# pool_size = as.integer(args[3])
# repeat_time = as.integer(args[4])
# set_name = args[5]
# noise_level = args[6]
# anti_pool = args[7]
# measure = args[8]
add = 3
iter_num = 10
pool_size = 500
repeat_time = 1
set_name = 1
noise_level = 2
anti_pool = "true"
measure = "relative"
start_size = 50
# used to get the range of output
data_all = read.csv(file.path(data_path,paste(set_name,".csv",sep="")), header=TRUE)
data_all = as.matrix(data_all[sample(nrow(data_all)),])
std = noise_level*0.01
train = data_all[1:start_size,]
pool_all = data_all[(start_size+1):(start_size+1000),]
pool = pool_all[1:500,]
benchmark = data_all[(start_size+1000):nrow(data_all),]
source(file.path(helper_path,"predict_benchmark.R"))
source(file.path(helper_path,"compute_kernel.R"))
source(file.path(helper_path,"predict_benchmark.R"))
source(file.path(helper_path,"compute_kernel.R"))
source(file.path(helper_path,"predict_benchmark.R"))
xx= train[,1:2]
y= train[,3]
fit=mlegp(xx,y)
inverse=fit$invVarMatrix
d=fit[["numDim"]]
beta=fit[["beta"]]
sigma=fit[["sig2"]]
mu=fit[["mu"]]
nugget=fit[["nugget"]]
number=fit[["numObs"]]
fitZ = fit$Z
errors[p] =  predict_benchmark(d,beta,sigma, train,benchmark,inverse,mu, nugget, fitZ,unfold=FALSE)
errors
out = predict_benchmark(d,beta,sigma, train,benchmark,inverse,mu, nugget, fitZ,unfold=TRUE)
pred = predict(fit, benchmark[,1:2], se.fit=TRUE)
mean_pred = pred$fit
var_pred = (pred$se.fit)^2
nrow(out)
length(out)
nrow(benchmark)
plot(out[1:3851],mean_pred)
plot(out[3851:7702],var_pred)
plot(out[3852:7702],var_pred)
setwd("~/OED_all/OED_multiple_surface/src/Random")
setwd("~/OED_all/OED_multiple_surface/src/Random")
setwd("~/OED_all/OED_multiple_surface/src/Random")
source("../setpath.R")
library(mlegp)
# args = commandArgs(TRUE)
# add = as.integer(args[1])
# iter_num = as.integer(args[2])
# pool_size = as.integer(args[3])
# repeat_time = as.integer(args[4])
# set_name = args[5]
# noise_level = args[6]
# anti_pool = args[7]
# measure = args[8]
add = 3
iter_num = 10
pool_size = 500
repeat_time = 1
set_name = 1
noise_level = 2
anti_pool = "true"
measure = "relative"
start_size = 50
# used to get the range of output
data_all = read.csv(file.path(data_path,paste(set_name,".csv",sep="")), header=TRUE)
data_all = as.matrix(data_all[sample(nrow(data_all)),])
std = noise_level*0.01
train = data_all[1:start_size,]
pool_all = data_all[(start_size+1):(start_size+1000),]
pool = pool_all[1:500,]
benchmark = data_all[(start_size+1000):nrow(data_all),]
errors = as.numeric()
p=1
xx= train[,1:2]
y= train[,3]
fit=mlegp(xx,y)
inverse=fit$invVarMatrix
errors[p] =  predict_benchmark(fit,train,benchmark,unfold=FALSE)
head(train)
source(file.path(helper_path,"compute_kernel.R"))
source(file.path(helper_path,"predict_benchmark.R"))
xx= train[,1:2]
y= train[,3]
fit=mlegp(xx,y)
inverse=fit$invVarMatrix
errors[p] =  predict_benchmark(fit,train,benchmark,unfold=FALSE)
out = predict_benchmark(fit,train,benchmark,unfold=TRUE)
pred = predict(fit, benchmark[,1:2], se.fit=TRUE)
mean_pred = pred$fit
var_pred = (pred$se.fit)^2
dim(benchmark)
plot(out[1:3851],mean_pred)
rm(list =ls())
setwd("~/OED_all/OED_multiple_surface/src/Random")
source("../setpath.R")
library(mlegp)
# args = commandArgs(TRUE)
# add = as.integer(args[1])
# iter_num = as.integer(args[2])
# pool_size = as.integer(args[3])
# repeat_time = as.integer(args[4])
# set_name = args[5]
# noise_level = args[6]
# anti_pool = args[7]
# measure = args[8]
add = 3
iter_num = 10
pool_size = 500
repeat_time = 1
set_name = 1
noise_level = 2
anti_pool = "true"
measure = "relative"
start_size = 50
# used to get the range of output
data_all = read.csv(file.path(data_path,paste(set_name,".csv",sep="")), header=TRUE)
data_all = as.matrix(data_all[sample(nrow(data_all)),])
std = noise_level*0.01
train = data_all[1:start_size,]
pool_all = data_all[(start_size+1):(start_size+1000),]
pool = pool_all[1:500,]
benchmark = data_all[(start_size+1000):nrow(data_all),]
errors = as.numeric()
ptm <- proc.time()
source(file.path(helper_path,"compute_kernel.R"))
source(file.path(helper_path,"predict_benchmark.R"))
xx= train[,1:2]
y= train[,3]
fit=mlegp(xx,y)
inverse=fit$invVarMatrix
errors[p] =  predict_benchmark(fit,train,benchmark,unfold=FALSE)
p=1
xx= train[,1:2]
y= train[,3]
fit=mlegp(xx,y)
inverse=fit$invVarMatrix
errors[p] =  predict_benchmark(fit,train,benchmark,unfold=FALSE)
out = predict_benchmark(fit,train,benchmark,unfold=TRUE)
pred = predict(fit, benchmark[,1:2], se.fit=TRUE)
mean_pred = pred$fit
var_pred = (pred$se.fit)^2
dim(benchmark)
plot(out[1:3851],mean_pred)
remove = seq(1,add,1)
leftpool = pool[-remove,]
dim(pool)
dim(leftpool)
remove = seq(1,add,1)
pool = pool[-remove,]
dim(pool)
pool = rbind(pool,pool_all[1:add,])
dim(pool)
a = 1
b=2
l = list(a,b)
l$a
l
l = list("a" = a,"b" = b)
l
l$a
rnorm(3,2)
rnorm(6,2)
setwd("~/OED_all/OED_multiple_surface/src/Random")
source("../setpath.R")
library(mlegp)
# args = commandArgs(TRUE)
# add = as.integer(args[1])
# iter_num = as.integer(args[2])
# pool_size = as.integer(args[3])
# repeat_time = as.integer(args[4])
# set_name = args[5]
# noise_level = args[6]
# anti_pool = args[7]
# measure = args[8]
add = 3
iter_num = 10
pool_size = 500
random_seed= 1
set_name = 1
noise_level = 2
start_size = 50
file_path = file.path(data_path,paste(set_name,".csv",sep=""))
source(file.path(helper_path,"prepare_train"))
source(file.path(helper_path,"prepare_train.R"))
data = prepare_train(file_path,random_seed,start_size,noise_level,pool_size = 1500)
data = prepare_train(file_path,random_seed,start_size,noise_level)
train = data$train
pool = data$pool
pool_all = data$pool_all
benchmark = data$benchmark
head(train)
head(pool)
head(pool_all)
head(benchmark)
errors = as.numeric()
ptm <- proc.time()
source(file.path(helper_path,"compute_kernel.R"))
source(file.path(helper_path,"predict_benchmark.R"))
p = 1

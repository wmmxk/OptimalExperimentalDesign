#test the prediction on benchmark set
# df is the train in current around
# dat is the benchmark set
newcov=matrix(nrow=dim(dat)[1],ncol=number)
i=1
for ( i in 1:dim(dat)[1])
{
j=1
for (j in 1:number)
{
k=1
dist=0
for (k in 1:d)
{
dist=dist-(dat[i,k]-df[j,k])^2*beta[k]
}
newcov[i,j]=sigma*exp(dist)
}
}
diag(newcov)=diag(newcov)+nugget
mean=newcov%*%inverse%*%(fit$Z - fit$mu)+mu[1]
real=dat[,3]
var=diag(sigma+nugget-newcov%*%inverse%*%t(newcov))
mean(abs((mean-real)/real))
source("../setpath.R")
library(mlegp)
# args = commandArgs(TRUE)
# add = as.integer(args[1])
# iter_num = as.integer(args[2])
add = 1
iter_num = 120
data= as.matrix(read.csv(file.path(out_data_path,"GPsynthetic1.csv"), header=TRUE))
train= read.csv(file.path(out_data_path,"entropy_train.csv"), header=TRUE)
# bencharmark set
dat= as.matrix(read.csv(file.path(out_data_path,"GPsynthetic2.csv"), header=TRUE))
errors = as.numeric()
ptm <- proc.time()
for (p in 1:iter_num)
{
xx=as.matrix(train[,1:2])
y=as.matrix(train[,3])
fit=mlegp(xx,y)
#fit=mlegp(xx,y,nugget=1,nugget.known=1)
inverse=fit$invVarMatrix
d=fit[["numDim"]]
beta=fit[["beta"]]
sigma=fit[["sig2"]]
mu=fit[["mu"]]
nugget=fit[["nugget"]]
number=fit[["numObs"]]
df=as.matrix(train)
newcov=matrix(nrow=dim(data)[1],ncol=number)
for ( i in 1:dim(data)[1])
{
j=1
for (j in 1:number)
{
k=1
dist=0
for (k in 1:d)
{
dist=dist-(data[i,k]-df[j,k])^2*beta[k]
}
newcov[i,j]=sigma*exp(dist)
}
}
diag(newcov)=diag(newcov)+nugget
mean=newcov%*%inverse%*%(fit$Z - fit$mu)+mu[1]
real=data[,3]
var=diag(sigma+nugget-newcov%*%inverse%*%t(newcov))
index=sort(var, decreasing = TRUE,index.return=TRUE)$ix
# select the top add rows and add them to train. (caveat: when indexing one row,keep the dimension)
adddata=data[index[1:add],1:3,drop=FALSE]
train=t(data.frame(t(train),t(adddata)))
total=1:dim(data)[1]
remove=index[1:add]
left=total[!total%in%remove]
lefttrain=data[left,]
# update the pool
data = lefttrain
#test the prediction on benchmark set
# df is the train in current around
# dat is the benchmark set
newcov=matrix(nrow=dim(dat)[1],ncol=number)
i=1
for ( i in 1:dim(dat)[1])
{
j=1
for (j in 1:number)
{
k=1
dist=0
for (k in 1:d)
{
dist=dist-(dat[i,k]-df[j,k])^2*beta[k]
}
newcov[i,j]=sigma*exp(dist)
}
}
diag(newcov)=diag(newcov)+nugget
mean=newcov%*%inverse%*%(fit$Z - fit$mu)+mu[1]
real=dat[,3]
var=diag(sigma+nugget-newcov%*%inverse%*%t(newcov))
errors[p] = mean(abs((mean-real)/real))
p=p+1
}
time
errors
backup = train
nrow(train)
train = backup[1:52,]
xx=as.matrix(train[,1:2])
y=as.matrix(train[,3])
fit=mlegp(xx,y)
#fit=mlegp(xx,y,nugget=1,nugget.known=1)
inverse=fit$invVarMatrix
d=fit[["numDim"]]
beta=fit[["beta"]]
sigma=fit[["sig2"]]
mu=fit[["mu"]]
nugget=fit[["nugget"]]
number=fit[["numObs"]]
df=as.matrix(train)
newcov=matrix(nrow=dim(data)[1],ncol=number)
for ( i in 1:dim(data)[1])
{
j=1
for (j in 1:number)
{
k=1
dist=0
for (k in 1:d)
{
dist=dist-(data[i,k]-df[j,k])^2*beta[k]
}
newcov[i,j]=sigma*exp(dist)
}
}
diag(newcov)=diag(newcov)+nugget
mean=newcov%*%inverse%*%(fit$Z - fit$mu)+mu[1]
real=data[,3]
var=diag(sigma+nugget-newcov%*%inverse%*%t(newcov))
index=sort(var, decreasing = TRUE,index.return=TRUE)$ix
# select the top add rows and add them to train. (caveat: when indexing one row,keep the dimension)
adddata=data[index[1:add],1:3,drop=FALSE]
train=t(data.frame(t(train),t(adddata)))
total=1:dim(data)[1]
remove=index[1:add]
left=total[!total%in%remove]
lefttrain=data[left,]
# update the pool
data = lefttrain
#test the prediction on benchmark set
# df is the train in current around
# dat is the benchmark set
newcov=matrix(nrow=dim(dat)[1],ncol=number)
i=1
for ( i in 1:dim(dat)[1])
{
j=1
for (j in 1:number)
{
k=1
dist=0
for (k in 1:d)
{
dist=dist-(dat[i,k]-df[j,k])^2*beta[k]
}
newcov[i,j]=sigma*exp(dist)
}
}
diag(newcov)=diag(newcov)+nugget
mean=newcov%*%inverse%*%(fit$Z - fit$mu)+mu[1]
real=dat[,3]
var=diag(sigma+nugget-newcov%*%inverse%*%t(newcov))
mean(abs((mean-real)/real))
train
errors
sample(1:20,3)
sample(1:20,3,replace = FALSE)
start_size = 20
select = sample(1:nrow(data), start_size)
left = data[-select,]
head(left)
dim(left)
data = read.csv(file.path(data_path,"surface.csv"), header=FALSE)
dim(data)
start_size = 20
select = sample(1:nrow(data), start_size)
write.csv(data[select,], file.path(out_data_path,"entropy_train.csv"),row.names=FALSE)
left = data[-select,]
dim(left)
random_seed=1
set.seed(random_seed)
data = read.csv(file.path(data_path,"surface.csv"), header=FALSE)
start_size = 20
select = sample(1:nrow(data), start_size)
select
random_seed=2
set.seed(random_seed)
data = read.csv(file.path(data_path,"surface.csv"), header=FALSE)
start_size = 20
select = sample(1:nrow(data), start_size)
select
random_seed=3
set.seed(random_seed)
data = read.csv(file.path(data_path,"surface.csv"), header=FALSE)
start_size = 20
select = sample(1:nrow(data), start_size)
select
setwd("~/OED_all/OED_multiple_surface/src/EN")
setwd("~/OED_all/OED_multiple_surface/src/Random")
setwd("~/OED_all/OED_multiple_surface/src/Random")
source("../setpath.R")
library(mlegp)
# args = commandArgs(TRUE)
# add = as.integer(args[1])
# iter_num = as.integer(args[2])
# pool_size = as.integer(args[3])
# repeat_time = as.integer(args[4])
# set_name = args[5]
# noise_level = args[6]
# anti_pool = args[7]
# measure = args[8]
add = 3
iter_num = 10
pool_size = 500
repeat_time = 1
set_name = 1
noise_level = 2
anti_pool = "true"
measure = "relative"
data_path
paste(set_name,".csv",sep="")
all_surface = read.csv(file.path(data_path,paste(set_name,".csv",sep=""), header=TRUE))
all_surface = read.csv(file.path(data_path,paste(set_name,".csv",sep="")), header=TRUE)
head(all_surface)
a = c(1,2,3)
sample(a)
sample(a)
sample(a)
sample(a)
start_size = 50
# used to get the range of output
data_all = read.csv(file.path(data_path,paste(set_name,".csv",sep="")), header=TRUE)
data_all = as.matrix(data[sample(nrow(data_all)),])
std = noise_level*0.01
train = data_all[1:start_size,]
pool_all = data_all[(start_size+1):(start_size+1000),]
benchmark = data_all[(start_size+1000):nrow(data_all),]
head(train)
p=1
source(file.path(helper_path,"predict_benchmark.R"))
xx= train[,1:2]
y= train[,3]
fit=mlegp(xx,y)
inverse=fit$invVarMatrix
d=fit[["numDim"]]
beta=fit[["beta"]]
sigma=fit[["sig2"]]
mu=fit[["mu"]]
nugget=fit[["nugget"]]
number=fit[["numObs"]]
fitZ = fit$Z
df=as.matrix(train)
pool = pool_all[1:500,]
adddata=pool[1:add,1:3,drop=FALSE]
setwd("~/OED_all/OED_multiple_surface/src/Sanity")
setwd("~/OED_all/OED_multiple_surface/src/Sanity")
source("../setpath.R")
library(mlegp)
data_all = read.csv(file.path(data_path,paste(set_name,".csv",sep="")), header=TRUE)
data_all = as.matrix(data[sample(nrow(data_all)),])
std = noise_level*0.01
train = data_all[1:start_size,]
xx= train[,1:2]
y= train[,3]
fit=mlegp(xx,y)
#fit=mlegp(xx,y,nugget=1,nugget.known=1)
inverse=fit$invVarMatrix
nugget=fit[["nugget"]]
nugget
train = rbind(train,train,train)
train[,3]
rnorm
train[,3] = train[,3] + rnorm(nrow(train),sd=0.05)
xx= train[,1:2]
y= train[,3]
fit=mlegp(xx,y)
xx= train[,1:2]
y= train[,3]
fit=mlegp(xx,y)
#fit=mlegp(xx,y,nugget=1,nugget.known=1)
inverse=fit$invVarMatrix
d=fit[["numDim"]]
beta=fit[["beta"]]
sigma=fit[["sig2"]]
mu=fit[["mu"]]
nugget=fit[["nugget"]]
number=fit[["numObs"]]
fitZ = fit$Z
df=as.matrix(train)
number
dim(train)
nugget
train = data_all[1:start_size,]
train = rbind(train,train,train)
train[,3] = train[,3] + rnorm(nrow(train),sd=0.09)
xx= train[,1:2]
y= train[,3]
fit=mlegp(xx,y)
#fit=mlegp(xx,y,nugget=1,nugget.known=1)
inverse=fit$invVarMatrix
d=fit[["numDim"]]
beta=fit[["beta"]]
sigma=fit[["sig2"]]
mu=fit[["mu"]]
nugget=fit[["nugget"]]
number=fit[["numObs"]]
fitZ = fit$Z
df=as.matrix(train)
nugget
source(file.path(helper_path,"predict_benchmark.R"))
res = predict_benchmark(inverse,d,beta,sigma, mu, nugget, nubmer,fitZ,df,train,unfold=TRUE)
mean = res[1:(length(res)/2)]
var = res[(length(res)/2+1):length(res)]
real=data[,3]
plot(mean,real)
real=train[,3]
plot(mean,real)
data = data_all[(start_size+1):(start_size+100),]
res = predict_benchmark(inverse,d,beta,sigma, mu, nugget, nubmer,fitZ,df,data,unfold=TRUE)
mean = res[1:(length(res)/2)]
var = res[(length(res)/2+1):length(res)]
real=data[,3]
plot(mean,real)
pred = predict(fit, data[,1:2], se.fit=TRUE)
mean_pred = pred$fit
var_pred = (pred$se.fit)^2
plot(mean,mean_pred)
setwd("~/OED_all/OED_multiple_surface/src/Sanity")
source("../setpath.R")
library(mlegp)
set_name = 1
start_size = 20
data_all = read.csv(file.path(data_path,paste(set_name,".csv",sep="")), header=TRUE)
data_all = as.matrix(data[sample(nrow(data_all)),])
std = noise_level*0.01
train = data_all[1:start_size,]
train = rbind(train,train,train)
train[,3] = train[,3] + rnorm(nrow(train),sd=0.09)
data = data_all[(start_size+1):(start_size+500),]
xx= train[,1:2]
y= train[,3]
fit=mlegp(xx,y)
#fit=mlegp(xx,y,nugget=1,nugget.known=1)
inverse=fit$invVarMatrix
d=fit[["numDim"]]
beta=fit[["beta"]]
sigma=fit[["sig2"]]
mu=fit[["mu"]]
nugget=fit[["nugget"]]
number=fit[["numObs"]]
fitZ = fit$Z
df=as.matrix(train)
source(file.path(helper_path,"predict_benchmark.R"))
res = predict_benchmark(inverse,d,beta,sigma, mu, nugget, nubmer,fitZ,df,data,unfold=TRUE)
mean = res[1:(length(res)/2)]
var = res[(length(res)/2+1):length(res)]
real=data[,3]
# This is the predicted mean and variance by the interface coming with the package
pred = predict(fit, data[,1:2], se.fit=TRUE)
mean_pred = pred$fit
var_pred = (pred$se.fit)^2
plot(mean,mean_pred)
plot(var_pred,var)
plot(var_pred,var)
plot(mean_pred, mean)
plot(real, mean)
plot(real, mean_pred)
setwd("~/OED_all/OED_multiple_surface/src/Sanity")
source("../setpath.R")
library(mlegp)
set_name = 1
start_size = 20
data_all = read.csv(file.path(data_path,paste(set_name,".csv",sep="")), header=TRUE)
data_all = as.matrix(data[sample(nrow(data_all)),])
std = noise_level*0.01
train = data_all[1:start_size,]
train = rbind(train,train,train)
train[,3] = train[,3] + rnorm(nrow(train),sd=0.09)
data = data_all[(start_size+1):(start_size+500),]
xx= train[,1:2]
y= train[,3]
fit=mlegp(xx,y)
#fit=mlegp(xx,y,nugget=1,nugget.known=1)
inverse=fit$invVarMatrix
d=fit[["numDim"]]
beta=fit[["beta"]]
sigma=fit[["sig2"]]
mu=fit[["mu"]]
nugget=fit[["nugget"]]
number=fit[["numObs"]]
fitZ = fit$Z
df=as.matrix(train)
source(file.path(helper_path,"predict_benchmark.R"))
res = predict_benchmark(inverse,d,beta,sigma, mu, nugget, nubmer,fitZ,df,data,unfold=TRUE)
mean = res[1:(length(res)/2)]
var = res[(length(res)/2+1):length(res)]
real=data[,3]
# This is the predicted mean and variance by the interface coming with the package
pred = predict(fit, data[,1:2], se.fit=TRUE)
mean_pred = pred$fit
var_pred = (pred$se.fit)^2
setwd("~/OED_all/OED_multiple_surface/src/Sanity")
source("../setpath.R")
library(mlegp)
set_name = 1
start_size = 20
data_all = read.csv(file.path(data_path,paste(set_name,".csv",sep="")), header=TRUE)
data_all = as.matrix(data[sample(nrow(data_all)),])
std = noise_level*0.01
train = data_all[1:start_size,]
train = rbind(train,train,train)
train[,3] = train[,3] + rnorm(nrow(train),sd=0.09)
data = data_all[(start_size+1):(start_size+500),]
xx= train[,1:2]
y= train[,3]
fit=mlegp(xx,y)
#fit=mlegp(xx,y,nugget=1,nugget.known=1)
inverse=fit$invVarMatrix
d=fit[["numDim"]]
beta=fit[["beta"]]
sigma=fit[["sig2"]]
mu=fit[["mu"]]
nugget=fit[["nugget"]]
number=fit[["numObs"]]
fitZ = fit$Z
df=as.matrix(train)
source(file.path(helper_path,"predict_benchmark.R"))
res = predict_benchmark(inverse,d,beta,sigma, mu, nugget, nubmer,fitZ,df,data,unfold=TRUE)
mean = res[1:(length(res)/2)]
var = res[(length(res)/2+1):length(res)]
real=data[,3]
# This is the predicted mean and variance by the interface coming with the package
pred = predict(fit, data[,1:2], se.fit=TRUE)
mean_pred = pred$fit
var_pred = (pred$se.fit)^2
plot(var_pred,var)
plot(mean_pred, mean)
length(mean)
plot(mean_pred, mean)
plot(real, mean)
plot(real, mean_pred)
set_name = 1
start_size = 50
data_all = read.csv(file.path(data_path,paste(set_name,".csv",sep="")), header=TRUE)
data_all = as.matrix(data[sample(nrow(data_all)),])
std = noise_level*0.01
train = data_all[1:start_size,]
train = rbind(train,train,train)
train[,3] = train[,3] + rnorm(nrow(train),sd=0.09)
data = data_all[(start_size+1):(start_size+500),]
xx= train[,1:2]
y= train[,3]
fit=mlegp(xx,y)
#fit=mlegp(xx,y,nugget=1,nugget.known=1)
inverse=fit$invVarMatrix
d=fit[["numDim"]]
beta=fit[["beta"]]
sigma=fit[["sig2"]]
mu=fit[["mu"]]
nugget=fit[["nugget"]]
number=fit[["numObs"]]
fitZ = fit$Z
df=as.matrix(train)
source(file.path(helper_path,"predict_benchmark.R"))
res = predict_benchmark(inverse,d,beta,sigma, mu, nugget, nubmer,fitZ,df,data,unfold=TRUE)
mean = res[1:(length(res)/2)]
var = res[(length(res)/2+1):length(res)]
real=data[,3]
# This is the predicted mean and variance by the interface coming with the package
pred = predict(fit, data[,1:2], se.fit=TRUE)
mean_pred = pred$fit
var_pred = (pred$se.fit)^2
data_all = read.csv(file.path(data_path,paste(set_name,".csv",sep="")), header=TRUE)
data_all = as.matrix(data[sample(nrow(data_all)),])
std = noise_level*0.01
train = data_all[1:start_size,]
train = rbind(train,train,train)
train[,3] = train[,3] + rnorm(nrow(train),sd=0.09)
data = data_all[(start_size+1):(start_size+500),]
xx= train[,1:2]
y= train[,3]
fit=mlegp(xx,y)
#fit=mlegp(xx,y,nugget=1,nugget.known=1)
inverse=fit$invVarMatrix
d=fit[["numDim"]]
beta=fit[["beta"]]
sigma=fit[["sig2"]]
mu=fit[["mu"]]
nugget=fit[["nugget"]]
number=fit[["numObs"]]
fitZ = fit$Z
df=as.matrix(train)
source(file.path(helper_path,"predict_benchmark.R"))
res = predict_benchmark(inverse,d,beta,sigma, mu, nugget, nubmer,fitZ,df,data,unfold=TRUE)
mean = res[1:(length(res)/2)]
var = res[(length(res)/2+1):length(res)]
real=data[,3]
# This is the predicted mean and variance by the interface coming with the package
pred = predict(fit, data[,1:2], se.fit=TRUE)

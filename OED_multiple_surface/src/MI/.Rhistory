data = lefttrain
#test the prediction on benchmark set
# df is the train in current around
# dat is the benchmark set
errors[p] =  predict_benchmark(inverse,d,beta,sigma, mu, nugget, nubmer,fitZ,df,dat)
}
time=proc.time() -ptm
write.csv(errors,file=file.path(out_data_path,paste("errors",repeat_time,set_name,sep=""),"Random",paste("every_",add,"_",iter_num,"_iter.csv",sep="")))
write.csv(train,file=file.path(out_data_path,paste("errors",repeat_time,set_name,sep=""),"Random",paste("train_every_",add,"_",iter_num,"_iter.csv",sep="")))
#
errors
setwd("~/OED_linux/src/MI")
source("../setpath.R")
require(MASS)
library(mlegp)
# args = commandArgs(TRUE)
# add = as.integer(args[1])
# iter_num = as.integer(args[2])
# pool_size = as.integer(args[3])
# repeat_time = as.integer(args[4])
# set_name = args[5]
add = 1
iter_num = 6
pool_size = 500
repeat_time = 1
set_name = "syn"
data_all= as.matrix(read.csv(file.path(out_data_path,"train_pool",set_name,"GPsynthetic1.csv"), header=TRUE))
data = data_all[1:pool_size,]
train= read.csv(file.path(out_data_path,"entropy_train.csv"), header=TRUE)
# bencharmark set
dat= as.matrix(read.csv(file.path(out_data_path,"GPsynthetic2.csv"), header=TRUE))
errors = as.numeric()
ptm <- proc.time()
source(file.path(helper_path,"predict_benchmark.R"))
for (p in 1:iter_num)
{
xx=as.matrix(train[,1:2])
y=as.matrix(train[,3])
fit=mlegp(xx,y)
#fit=mlegp(xx,y,nugget=1,nugget.known=1)
inverse=fit$invVarMatrix
d=fit[["numDim"]]
beta=fit[["beta"]]
sigma=fit[["sig2"]]
mu=fit[["mu"]]
nugget=fit[["nugget"]]
number=fit[["numObs"]]
fitZ = fit$Z
df=as.matrix(train)
# compute the variance y/A
res =  predict_benchmark(inverse,d,beta,sigma, mu, nugget, nubmer,fitZ,df,data,unfold=TRUE)
var = res[(length(res)/2+1):length(res)]
# compute the variance y/(A bar)
# cov(A_bar, A_bar)
cov_unob =matrix(nrow=nrow(data),ncol=nrow(data))
for ( i in 1:nrow(data)) {
j=1
for (j in 1:nrow(data)) {
k=1
dist=0
for (k in 1:d) {
dist=dist-(data[i,k]-data[j,k])^2*beta[k]
}
cov_unob[i,j]=sigma*exp(dist)
}
}
diag(cov_unob)=diag(cov_unob) +  sigma + nugget
# compute denominator
divisor= as.numeric()
for (i in 1:nrow(data)) {
# invers_bar = solve(cov_unob[-i,-i])
invers_bar = chol2inv(chol(cov_unob[-i,-i]))
divisor[i] =  sigma+nugget - cov_unob[i,-i,drop=FALSE] %*% invers_bar %*% t(cov_unob[i,-i,drop=FALSE])
}
index=sort(var/divisor, decreasing = TRUE,index.return=TRUE)$ix
# select the top add rows and add them to train. (caveat: when indexing one row,keep the dimension)
adddata=data[index[1:add],1:3,drop=FALSE]
train=t(data.frame(t(train),t(adddata)))
total=1:dim(data)[1]
remove=index[1:add]
left=total[!total%in%remove]
lefttrain=data[left,]
# update the pool
data = rbind(lefttrain,data_all[(pool_size+(p-1)*add+1):(pool_size+p*add),])
#test the prediction on benchmark set
# df is the train in current around
# dat is the benchmark set
errors[p] =  predict_benchmark(inverse,d,beta,sigma, mu, nugget, nubmer,fitZ,df,dat)
}
setwd("~/OED_linux/src/MI")
setwd("~/OED_linux/src/MI")
source("../setpath.R")
require(MASS)
library(mlegp)
# args = commandArgs(TRUE)
# add = as.integer(args[1])
# iter_num = as.integer(args[2])
# pool_size = as.integer(args[3])
# repeat_time = as.integer(args[4])
# set_name = args[5]
add = 1
iter_num = 6
pool_size = 500
repeat_time = 1
set_name = "syn"
data_all= as.matrix(read.csv(file.path(out_data_path,"train_pool",set_name,"GPsynthetic1.csv"), header=TRUE))
data = data_all[1:pool_size,]
train= read.csv(file.path(out_data_path,"train_pool",set_name, "entropy_train.csv"), header=TRUE)
# bencharmark set
dat= as.matrix(read.csv(file.path(out_data_path, "train_pool",set_name,"GPsynthetic2.csv"), header=TRUE))
errors = as.numeric()
ptm <- proc.time()
source(file.path(helper_path,"predict_benchmark.R"))
for (p in 1:iter_num)
{
xx=as.matrix(train[,1:2])
y=as.matrix(train[,3])
fit=mlegp(xx,y)
#fit=mlegp(xx,y,nugget=1,nugget.known=1)
inverse=fit$invVarMatrix
d=fit[["numDim"]]
beta=fit[["beta"]]
sigma=fit[["sig2"]]
mu=fit[["mu"]]
nugget=fit[["nugget"]]
number=fit[["numObs"]]
fitZ = fit$Z
df=as.matrix(train)
# compute the variance y/A
res =  predict_benchmark(inverse,d,beta,sigma, mu, nugget, nubmer,fitZ,df,data,unfold=TRUE)
var = res[(length(res)/2+1):length(res)]
# compute the variance y/(A bar)
# cov(A_bar, A_bar)
cov_unob =matrix(nrow=nrow(data),ncol=nrow(data))
for ( i in 1:nrow(data)) {
j=1
for (j in 1:nrow(data)) {
k=1
dist=0
for (k in 1:d) {
dist=dist-(data[i,k]-data[j,k])^2*beta[k]
}
cov_unob[i,j]=sigma*exp(dist)
}
}
diag(cov_unob)=diag(cov_unob) +  sigma + nugget
# compute denominator
divisor= as.numeric()
for (i in 1:nrow(data)) {
# invers_bar = solve(cov_unob[-i,-i])
invers_bar = chol2inv(chol(cov_unob[-i,-i]))
divisor[i] =  sigma+nugget - cov_unob[i,-i,drop=FALSE] %*% invers_bar %*% t(cov_unob[i,-i,drop=FALSE])
}
index=sort(var/divisor, decreasing = TRUE,index.return=TRUE)$ix
# select the top add rows and add them to train. (caveat: when indexing one row,keep the dimension)
adddata=data[index[1:add],1:3,drop=FALSE]
train=t(data.frame(t(train),t(adddata)))
total=1:dim(data)[1]
remove=index[1:add]
left=total[!total%in%remove]
lefttrain=data[left,]
# update the pool
data = rbind(lefttrain,data_all[(pool_size+(p-1)*add+1):(pool_size+p*add),])
#test the prediction on benchmark set
# df is the train in current around
# dat is the benchmark set
errors[p] =  predict_benchmark(inverse,d,beta,sigma, mu, nugget, nubmer,fitZ,df,dat)
}
setwd("~/")
setwd("~/OED_linux/src/MI")
source("../setpath.R")
require(MASS)
library(mlegp)
# args = commandArgs(TRUE)
# add = as.integer(args[1])
# iter_num = as.integer(args[2])
# pool_size = as.integer(args[3])
# repeat_time = as.integer(args[4])
# set_name = args[5]
add = 1
iter_num = 6
pool_size = 500
repeat_time = 1
set_name = "syn"
data_all= as.matrix(read.csv(file.path(out_data_path,"train_pool",set_name,"GPsynthetic1.csv"), header=TRUE))
data = data_all[1:pool_size,]
train= read.csv(file.path(out_data_path,"train_pool",set_name, "entropy_train.csv"), header=TRUE)
# bencharmark set
dat= as.matrix(read.csv(file.path(out_data_path, "train_pool",set_name,"GPsynthetic2.csv"), header=TRUE))
errors = as.numeric()
ptm <- proc.time()
source(file.path(helper_path,"predict_benchmark.R"))
for (p in 1:iter_num)
{
xx=as.matrix(train[,1:2])
y=as.matrix(train[,3])
fit=mlegp(xx,y)
#fit=mlegp(xx,y,nugget=1,nugget.known=1)
inverse=fit$invVarMatrix
d=fit[["numDim"]]
beta=fit[["beta"]]
sigma=fit[["sig2"]]
mu=fit[["mu"]]
nugget=fit[["nugget"]]
number=fit[["numObs"]]
fitZ = fit$Z
df=as.matrix(train)
# compute the variance y/A
res =  predict_benchmark(inverse,d,beta,sigma, mu, nugget, nubmer,fitZ,df,data,unfold=TRUE)
var = res[(length(res)/2+1):length(res)]
# compute the variance y/(A bar)
# cov(A_bar, A_bar)
cov_unob =matrix(nrow=nrow(data),ncol=nrow(data))
for ( i in 1:nrow(data)) {
j=1
for (j in 1:nrow(data)) {
k=1
dist=0
for (k in 1:d) {
dist=dist-(data[i,k]-data[j,k])^2*beta[k]
}
cov_unob[i,j]=sigma*exp(dist)
}
}
diag(cov_unob)=diag(cov_unob) +  sigma + nugget
# compute denominator
divisor= as.numeric()
for (i in 1:nrow(data)) {
# invers_bar = solve(cov_unob[-i,-i])
invers_bar = chol2inv(chol(cov_unob[-i,-i]))
divisor[i] =  sigma+nugget - cov_unob[i,-i,drop=FALSE] %*% invers_bar %*% t(cov_unob[i,-i,drop=FALSE])
}
index=sort(var/divisor, decreasing = TRUE,index.return=TRUE)$ix
# select the top add rows and add them to train. (caveat: when indexing one row,keep the dimension)
adddata=data[index[1:add],1:3,drop=FALSE]
train=t(data.frame(t(train),t(adddata)))
total=1:dim(data)[1]
remove=index[1:add]
left=total[!total%in%remove]
lefttrain=data[left,]
# update the pool
data = rbind(lefttrain,data_all[(pool_size+(p-1)*add+1):(pool_size+p*add),])
#test the prediction on benchmark set
# df is the train in current around
# dat is the benchmark set
errors[p] =  predict_benchmark(inverse,d,beta,sigma, mu, nugget, nubmer,fitZ,df,dat)
}
time=proc.time() -ptm
cat("time",time)
write.csv(errors,file=file.path(out_data_path,paste("errors",repeat_time,set_name,sep=""),"MI",paste("every_",add,"_",iter_num,"_iter.csv",sep="")))
write.csv(train,file=file.path(out_data_path,paste("errors",repeat_time,set_name,sep=""),"MI",paste("train_every_",add,"_",iter_num,"_iter.csv",sep="")))
setwd("~/OED_linux/src/EN")
errors
setwd("~/OED_linux/src/EN")
source("../setpath.R")
library(mlegp)
# args = commandArgs(TRUE)
# add = as.integer(args[1])
# iter_num = as.integer(args[2])
# pool_size = as.integer(args[3])
# repeat_time = as.integer(args[4])
# set_name = args[5]
add = 1
iter_num = 20
pool_size = 500
repeat_time = 1
set_name = "syn"
data_all= as.matrix(read.csv(file.path(out_data_path,"train_pool",set_name,"GPsynthetic1.csv"), header=TRUE))
data = data_all[1:pool_size,]
train= read.csv(file.path(out_data_path,"train_pool",set_name, "entropy_train.csv"), header=TRUE)
# bencharmark set
dat= as.matrix(read.csv(file.path(out_data_path, "train_pool",set_name,"GPsynthetic2.csv"), header=TRUE))
errors = as.numeric()
ptm <- proc.time()
source(file.path(helper_path,"predict_benchmark.R"))
for (p in 1:iter_num)
{
xx=as.matrix(train[,1:2])
y=as.matrix(train[,3])
fit=mlegp(xx,y)
#fit=mlegp(xx,y,nugget=1,nugget.known=1)
inverse=fit$invVarMatrix
d=fit[["numDim"]]
beta=fit[["beta"]]
sigma=fit[["sig2"]]
mu=fit[["mu"]]
nugget=fit[["nugget"]]
number=fit[["numObs"]]
fitZ = fit$Z
df=as.matrix(train)
#predict on the pool
res =  predict_benchmark(inverse,d,beta,sigma, mu, nugget, nubmer,fitZ,df,data,unfold=TRUE)
var = res[(length(res)/2+1):length(res)]
index=sort(var, decreasing = TRUE,index.return=TRUE)$ix
# select the top add rows and add them to train. (caveat: when indexing one row,keep the dimension)
adddata=data[index[1:add],1:3,drop=FALSE]
train=t(data.frame(t(train),t(adddata)))
total=1:dim(data)[1]
remove=index[1:add]
left=total[!total%in%remove]
lefttrain=data[left,]
# update the pool by append another batch to the pool
data = rbind(lefttrain,data_all[(pool_size+(p-1)*add+1):(pool_size+p*add),])
#test the prediction on benchmark set
# df is the train in current around
# dat is the benchmark set
errors[p] =  predict_benchmark(inverse,d,beta,sigma, mu, nugget, nubmer,fitZ,df,dat)
}
time=proc.time() -ptm
cat("time",time)
write.csv(errors,file=file.path(out_data_path,paste("errors",repeat_time,set_name,sep=""),"EN",paste("every_",add,"_",iter_num,"_iter.csv",sep="")))
write.csv(train,file=file.path(out_data_path,paste("errors",repeat_time,set_name, sep=""),"EN",paste("train_every_",add,"_",iter_num,"_iter.csv",sep="")))
errors
setwd("~/OED_linux/src/EN")
source("../setpath.R")
library(mlegp)
# args = commandArgs(TRUE)
# add = as.integer(args[1])
# iter_num = as.integer(args[2])
# pool_size = as.integer(args[3])
# repeat_time = as.integer(args[4])
# set_name = args[5]
add = 1
iter_num = 20
pool_size = 500
repeat_time = 1
set_name = "syn"
data_all= as.matrix(read.csv(file.path(out_data_path,"train_pool",set_name,"GPsynthetic1.csv"), header=TRUE))
data = data_all[1:pool_size,]
train= read.csv(file.path(out_data_path,"train_pool",set_name, "entropy_train.csv"), header=TRUE)
# bencharmark set
dat= as.matrix(read.csv(file.path(out_data_path, "train_pool",set_name,"GPsynthetic2.csv"), header=TRUE))
errors = as.numeric()
ptm <- proc.time()
source(file.path(helper_path,"predict_benchmark.R"))
for (p in 1:iter_num)
{
xx=as.matrix(train[,1:2])
y=as.matrix(train[,3])
fit=mlegp(xx,y)
#fit=mlegp(xx,y,nugget=1,nugget.known=1)
inverse=fit$invVarMatrix
d=fit[["numDim"]]
beta=fit[["beta"]]
sigma=fit[["sig2"]]
mu=fit[["mu"]]
nugget=fit[["nugget"]]
number=fit[["numObs"]]
fitZ = fit$Z
df=as.matrix(train)
#predict on the pool
res =  predict_benchmark(inverse,d,beta,sigma, mu, nugget, nubmer,fitZ,df,data,unfold=TRUE)
var = res[(length(res)/2+1):length(res)]
index=sort(var, decreasing = TRUE,index.return=TRUE)$ix
# select the top add rows and add them to train. (caveat: when indexing one row,keep the dimension)
adddata=data[index[1:add],1:3,drop=FALSE]
train=t(data.frame(t(train),t(adddata)))
total=1:dim(data)[1]
remove=index[1:add]
left=total[!total%in%remove]
lefttrain=data[left,]
# update the pool by append another batch to the pool
data = rbind(lefttrain,data_all[(pool_size+(p-1)*add+1):(pool_size+p*add),])
#test the prediction on benchmark set
# df is the train in current around
# dat is the benchmark set
errors[p] =  predict_benchmark(inverse,d,beta,sigma, mu, nugget, nubmer,fitZ,df,dat)
}
time=proc.time() -ptm
cat("time",time)
write.csv(errors,file=file.path(out_data_path,paste("errors",repeat_time,set_name,sep=""),"EN",paste("every_",add,"_",iter_num,"_iter.csv",sep="")))
write.csv(train,file=file.path(out_data_path,paste("errors",repeat_time,set_name, sep=""),"EN",paste("train_every_",add,"_",iter_num,"_iter.csv",sep="")))
errors
setwd("~/OED_linux/src/MI")
source("../setpath.R")
require(MASS)
library(mlegp)
# args = commandArgs(TRUE)
# add = as.integer(args[1])
# iter_num = as.integer(args[2])
# pool_size = as.integer(args[3])
# repeat_time = as.integer(args[4])
# set_name = args[5]
add = 1
iter_num = 6
pool_size = 500
repeat_time = 1
set_name = "syn"
data_all= as.matrix(read.csv(file.path(out_data_path,"train_pool",set_name,"GPsynthetic1.csv"), header=TRUE))
data = data_all[1:pool_size,]
train= read.csv(file.path(out_data_path,"train_pool",set_name, "entropy_train.csv"), header=TRUE)
# bencharmark set
dat= as.matrix(read.csv(file.path(out_data_path, "train_pool",set_name,"GPsynthetic2.csv"), header=TRUE))
errors = as.numeric()
ptm <- proc.time()
source(file.path(helper_path,"predict_benchmark.R"))
for (p in 1:iter_num)
{
xx=as.matrix(train[,1:2])
y=as.matrix(train[,3])
fit=mlegp(xx,y)
#fit=mlegp(xx,y,nugget=1,nugget.known=1)
inverse=fit$invVarMatrix
d=fit[["numDim"]]
beta=fit[["beta"]]
sigma=fit[["sig2"]]
mu=fit[["mu"]]
nugget=fit[["nugget"]]
number=fit[["numObs"]]
fitZ = fit$Z
df=as.matrix(train)
# compute the variance y/A
res =  predict_benchmark(inverse,d,beta,sigma, mu, nugget, nubmer,fitZ,df,data,unfold=TRUE)
var = res[(length(res)/2+1):length(res)]
# compute the variance y/(A bar)
# cov(A_bar, A_bar)
cov_unob =matrix(nrow=nrow(data),ncol=nrow(data))
for ( i in 1:nrow(data)) {
j=1
for (j in 1:nrow(data)) {
k=1
dist=0
for (k in 1:d) {
dist=dist-(data[i,k]-data[j,k])^2*beta[k]
}
cov_unob[i,j]=sigma*exp(dist)
}
}
diag(cov_unob)=diag(cov_unob) +  sigma + nugget
# compute denominator
divisor= as.numeric()
for (i in 1:nrow(data)) {
# invers_bar = solve(cov_unob[-i,-i])
invers_bar = chol2inv(chol(cov_unob[-i,-i]))
divisor[i] =  sigma+nugget - cov_unob[i,-i,drop=FALSE] %*% invers_bar %*% t(cov_unob[i,-i,drop=FALSE])
}
index=sort(var/divisor, decreasing = TRUE,index.return=TRUE)$ix
# select the top add rows and add them to train. (caveat: when indexing one row,keep the dimension)
adddata=data[index[1:add],1:3,drop=FALSE]
train=t(data.frame(t(train),t(adddata)))
total=1:dim(data)[1]
remove=index[1:add]
left=total[!total%in%remove]
lefttrain=data[left,]
# update the pool
data = rbind(lefttrain,data_all[(pool_size+(p-1)*add+1):(pool_size+p*add),])
#test the prediction on benchmark set
# df is the train in current around
# dat is the benchmark set
errors[p] =  predict_benchmark(inverse,d,beta,sigma, mu, nugget, nubmer,fitZ,df,dat)
}
setwd("~/OED_linux/src/EN")
setwd("~/OED_linux/src/MI")
source("../setpath.R")
library(mlegp)
# args = commandArgs(TRUE)
# add = as.integer(args[1])
# iter_num = as.integer(args[2])
# pool_size = as.integer(args[3])
# repeat_time = as.integer(args[4])
# set_name = args[5]
add = 1
iter_num = 20
pool_size = 500
repeat_time = 1
set_name = "syn"
data_all= as.matrix(read.csv(file.path(out_data_path,"train_pool",set_name,"GPsynthetic1.csv"), header=TRUE))
data = data_all[1:pool_size,]
train= read.csv(file.path(out_data_path,"train_pool",set_name, "entropy_train.csv"), header=TRUE)
# bencharmark set
dat= as.matrix(read.csv(file.path(out_data_path, "train_pool",set_name,"GPsynthetic2.csv"), header=TRUE))
errors = as.numeric()
ptm <- proc.time()
source(file.path(helper_path,"predict_benchmark.R"))
for (p in 1:iter_num)
{
xx=as.matrix(train[,1:2])
y=as.matrix(train[,3])
fit=mlegp(xx,y)
#fit=mlegp(xx,y,nugget=1,nugget.known=1)
inverse=fit$invVarMatrix
d=fit[["numDim"]]
beta=fit[["beta"]]
sigma=fit[["sig2"]]
mu=fit[["mu"]]
nugget=fit[["nugget"]]
number=fit[["numObs"]]
fitZ = fit$Z
df=as.matrix(train)
#predict on the pool
res =  predict_benchmark(inverse,d,beta,sigma, mu, nugget, nubmer,fitZ,df,data,unfold=TRUE)
var = res[(length(res)/2+1):length(res)]
index=sort(var, decreasing = TRUE,index.return=TRUE)$ix
# select the top add rows and add them to train. (caveat: when indexing one row,keep the dimension)
adddata=data[index[1:add],1:3,drop=FALSE]
train=t(data.frame(t(train),t(adddata)))
total=1:dim(data)[1]
remove=index[1:add]
left=total[!total%in%remove]
lefttrain=data[left,]
# update the pool by append another batch to the pool
data = rbind(lefttrain,data_all[(pool_size+(p-1)*add+1):(pool_size+p*add),])
#test the prediction on benchmark set
# df is the train in current around
# dat is the benchmark set
errors[p] =  predict_benchmark(inverse,d,beta,sigma, mu, nugget, nubmer,fitZ,df,dat)
}
time=proc.time() -ptm
cat("time",time)
write.csv(errors,file=file.path(out_data_path,paste("errors",repeat_time,set_name,sep=""),"EN",paste("every_",add,"_",iter_num,"_iter.csv",sep="")))
write.csv(train,file=file.path(out_data_path,paste("errors",repeat_time,set_name, sep=""),"EN",paste("train_every_",add,"_",iter_num,"_iter.csv",sep="")))
errors
